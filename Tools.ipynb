{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tools.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQW2A7k4ZiIx3ScrJG/+Ne",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhetman/hackathon_2021/blob/imartsilenko/Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaTU4OUHa7tq"
      },
      "source": [
        "#. Duplicate  search with MSE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3auBlwTe0nZM"
      },
      "source": [
        "  \n",
        "import skimage.measure\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import imghdr\n",
        "\n",
        "\"\"\" \n",
        "Duplicate Image Finder (DIF): function that searches a given directory for images and finds duplicate/similar images among them.\n",
        "Outputs the number of found duplicate/similar image pairs with a list of the filenames having lower resolution.\n",
        "\"\"\"\n",
        "\n",
        "def compare_images(directory, show_imgs=True, similarity=\"high\", compression=50):\n",
        "    \"\"\"\n",
        "    directory (str).........folder to search for duplicate/similar images\n",
        "    show_imgs (bool)........True = shows the duplicate/similar images found in output\n",
        "                            False = doesn't show found images\n",
        "    similarity (str)........\"high\" = searches for duplicate images, more precise\n",
        "                            \"low\" = finds similar images\n",
        "    compression (int).......recommended not to change default value\n",
        "                            compression in px (height x width) of the images before being compared\n",
        "                            the higher the compression i.e. the higher the pixel size, the more computational ressources and time required                 \n",
        "    \"\"\"\n",
        "    # list where the found duplicate/similar images are stored\n",
        "    duplicates = []\n",
        "    lower_res = []\n",
        "    \n",
        "    imgs_matrix = create_imgs_matrix(directory, compression)\n",
        "\n",
        "    # search for similar images\n",
        "    if similarity == \"low\":\n",
        "        ref = 1000\n",
        "    # search for 1:1 duplicate images\n",
        "    else:\n",
        "        ref = 200\n",
        "\n",
        "    main_img = 0\n",
        "    compared_img = 1\n",
        "    nrows, ncols = compression, compression\n",
        "    srow_A = 0\n",
        "    erow_A = nrows\n",
        "    srow_B = erow_A\n",
        "    erow_B = srow_B + nrows       \n",
        "    \n",
        "    while erow_B <= imgs_matrix.shape[0]:\n",
        "        while compared_img < (len(image_files)):\n",
        "            # select two images from imgs_matrix\n",
        "            imgA = imgs_matrix[srow_A : erow_A, # rows\n",
        "                               0      : ncols]  # columns\n",
        "            imgB = imgs_matrix[srow_B : erow_B, # rows\n",
        "                               0      : ncols]  # columns\n",
        "            # compare the images\n",
        "            rotations = 0\n",
        "            while image_files[main_img] not in duplicates and rotations <= 3:\n",
        "                if rotations != 0:\n",
        "                    imgB = rotate_img(imgB)\n",
        "                err = mse(imgA, imgB)\n",
        "                if err < ref:\n",
        "                    if show_imgs == True:\n",
        "                        show_img_figs(imgA, imgB, err)\n",
        "                        show_file_info(compared_img, main_img)\n",
        "                    add_to_list(image_files[main_img], duplicates)\n",
        "                    check_img_quality(directory, image_files[main_img], image_files[compared_img], lower_res)\n",
        "                rotations += 1\n",
        "            srow_B += nrows\n",
        "            erow_B += nrows\n",
        "            compared_img += 1\n",
        "        \n",
        "        srow_A += nrows\n",
        "        erow_A += nrows\n",
        "        srow_B = erow_A\n",
        "        erow_B = srow_B + nrows\n",
        "        main_img += 1\n",
        "        compared_img = main_img + 1\n",
        "\n",
        "    msg = \"\\n***\\n DONE: found \" + str(len(duplicates))  + \" duplicate image pairs in \" + str(len(image_files)) + \" total images.\\n The following files have lower resolution:\"\n",
        "    print(msg)\n",
        "    return set(lower_res)\n",
        "\n",
        "# Function that searches the folder for image files, converts them to a matrix\n",
        "def create_imgs_matrix(directory, compression):\n",
        "    global image_files   \n",
        "    image_files = []\n",
        "    # create list of all files in directory     \n",
        "    folder_files = [filename for filename in os.listdir(directory)]  \n",
        "    \n",
        "    # create images matrix   \n",
        "    counter = 0\n",
        "    for filename in folder_files: \n",
        "        if not os.path.isdir(directory + filename) and imghdr.what(directory + filename):\n",
        "            img = cv2.imdecode(np.fromfile(directory + filename, dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "            if type(img) == np.ndarray:\n",
        "                img = img[...,0:3]\n",
        "                img = cv2.resize(img, dsize=(compression, compression), interpolation=cv2.INTER_CUBIC)\n",
        "                if counter == 0:\n",
        "                    imgs_matrix = img\n",
        "                    image_files.append(filename)\n",
        "                    counter += 1\n",
        "                else:\n",
        "                    imgs_matrix = np.concatenate((imgs_matrix, img))\n",
        "                    image_files.append(filename)\n",
        "    return imgs_matrix\n",
        "\n",
        "# Function that calulates the mean squared error (mse) between two image matrices\n",
        "def mse(imageA, imageB):\n",
        "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
        "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
        "    return err\n",
        "\n",
        "# Function that plots two compared image files and their mse\n",
        "def show_img_figs(imageA, imageB, err):\n",
        "    fig = plt.figure()\n",
        "    plt.suptitle(\"MSE: %.2f\" % (err))\n",
        "    # plot first image\n",
        "    ax = fig.add_subplot(1, 2, 1)\n",
        "    plt.imshow(imageA, cmap = plt.cm.gray)\n",
        "    plt.axis(\"off\")\n",
        "    # plot second image\n",
        "    ax = fig.add_subplot(1, 2, 2)\n",
        "    plt.imshow(imageB, cmap = plt.cm.gray)\n",
        "    plt.axis(\"off\")\n",
        "    # show the images\n",
        "    plt.show()\n",
        "\n",
        "#Function for rotating an image matrix by a 90 degree angle\n",
        "def rotate_img(image):\n",
        "    image = np.rot90(image, k=1, axes=(0, 1))\n",
        "    return image\n",
        "\n",
        "# Function for printing filename info of plotted image files\n",
        "def show_file_info(compared_img, main_img):\n",
        "    print(\"Duplicate file: \" + image_files[main_img] + \" and \" + image_files[compared_img])\n",
        "\n",
        "# Function for appending items to a list\n",
        "def add_to_list(filename, list):\n",
        "    list.append(filename)\n",
        "\n",
        "# Function for checking the quality of compared images, appends the lower quality image to the list\n",
        "def check_img_quality(directory, imageA, imageB, list):\n",
        "    size_imgA = os.stat(directory + imageA).st_size\n",
        "    size_imgB = os.stat(directory + imageB).st_size\n",
        "    if size_imgA > size_imgB:\n",
        "        add_to_list(imageB, list)\n",
        "    else:\n",
        "        add_to_list(imageA, list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgjLidkxbD9q"
      },
      "source": [
        "# Image resolution classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88xJWVbgbN3q"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "def classify_image_resolution(path):\n",
        "  image = Image.open(path)\n",
        "  quality = \"To Big\"\n",
        "  res = min(image.size)\n",
        "  if (res < 600 ): quality = \"Bad\"\n",
        "  elif ( res < 1240): quality = \"Normal\"\n",
        "  elif ( res < 2080): quality = \"Good\"\n",
        "  elif ( res < 4160): quality = \"Perfect\"\n",
        "  return quality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Dwj7EdpbNC"
      },
      "source": [
        "# Проверка четкости изображения\n",
        "\n",
        "Идея в том, что нечеткое изображение уже посути является заблюренны (отсутствуют границы цветов).\n",
        "Введем некий коэфициент наличия границ. для нечеткого изображения после блюринга коэфициент не очень поменяется. Для четкого же, разница будет более заметной."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_Fu_8hMp0EJ"
      },
      "source": [
        "# Для параметров определения границ зададим функцию определения матрицы:\n",
        "# Под параметром n задаем количество пикселей, которые включаем в оценку границ. \n",
        "# Ориентация матрицы может быть горизонтальной или вертикальной.\n",
        "# Для нашей задачи нужно наверное не все пиксели \n",
        "\n",
        "def edges(n, orient):\n",
        "    edges = np.ones((2*n, 2*n, 3))\n",
        "    \n",
        "    if orient == 'vert':\n",
        "        for i in range(0, 2*n):\n",
        "            edges[i][n: 2*n] *= -1\n",
        "    elif orient == 'horiz':\n",
        "        edges[n: 2*n] *= -1\n",
        "    \n",
        "    return edges\n",
        "\n",
        "\n",
        "# Apply one filter defined by parameters W and single slice\n",
        "def conv_single_step(a_slice_prev, W):\n",
        "    s = W * a_slice_prev\n",
        "    Z = np.sum(s)\n",
        "    Z = np.abs(Z)\n",
        "    \n",
        "    return Z\n",
        "   \n",
        "# Full edge filter\n",
        "def conv_forward(A_prev, W, hparameters):\n",
        "    m = len(A_prev)\n",
        "    (f, f, n_C) = W.shape\n",
        "    stride = hparameters['stride']\n",
        "    pad = hparameters['pad']\n",
        "    \n",
        "    Z = list()\n",
        "    flag = 0\n",
        "    z_max = hparameters['z_max']\n",
        "    \n",
        "    if len(z_max) == 0:\n",
        "        z_max = list()\n",
        "        flag = 1\n",
        "    \n",
        "    for i in range(m):\n",
        "        \n",
        "        (x0, x1, x2) = A_prev[i].shape\n",
        "        A_prev_pad = A_prev[i][ \n",
        "                            int(x0 / 4) : int(x0 * 3 / 4), \n",
        "                            int(x1 / 4) : int(x1 * 3 / 4), \n",
        "                            :]\n",
        "        \n",
        "        (n_H_prev, n_W_prev, n_C_prev) = A_prev_pad.shape\n",
        "        n_H = int((n_H_prev - f + 2*pad) / stride) + 1\n",
        "        n_W = int((n_W_prev - f + 2*pad) / stride) + 1\n",
        "        z = np.zeros((n_H, n_W))\n",
        "        \n",
        "        a_prev_pad = A_prev_pad\n",
        "        \n",
        "        for h in range(n_H):\n",
        "            vert_start = h * stride\n",
        "            vert_end = h * stride + f\n",
        "            \n",
        "            for w in range(n_W):\n",
        "                horiz_start = w * stride\n",
        "                horiz_end = w * stride + f\n",
        "                \n",
        "               \n",
        "                a_slice_prev = a_prev_pad[vert_start: vert_end, horiz_start: horiz_end, :]\n",
        "\n",
        "                weights = W[:, :, :]\n",
        "                z[h, w] = conv_single_step(a_slice_prev, weights)\n",
        "        \n",
        "        if flag == 1:\n",
        "            z_max.append(np.max(z))\n",
        "        Z.append(z / z_max[i])\n",
        "        \n",
        "    cache = (A_prev, W, hparameters)\n",
        "    \n",
        "    return Z, z_max, cache\n",
        "\n",
        "# pooling\n",
        "def pool_forward(A_prev, hparameters, mode = 'max'):\n",
        "    m = len(A_prev)\n",
        "    f = hparameters['f']\n",
        "    stride = hparameters['stride']\n",
        "    \n",
        "    A = list()\n",
        "    \n",
        "    for i in range(m):\n",
        "        (n_H_prev, n_W_prev) = A_prev[i].shape\n",
        "        \n",
        "        n_H = int(1 + (n_H_prev - f) / stride)\n",
        "        n_W = int(1 + (n_W_prev - f) / stride)\n",
        "        \n",
        "        a = np.zeros((n_H, n_W))\n",
        "        \n",
        "        for h in range(n_H):\n",
        "            vert_start = h * stride\n",
        "            vert_end = h * stride + f\n",
        "            \n",
        "            for w in range(n_W):\n",
        "                horiz_start = w * stride\n",
        "                horiz_end = w * stride + f\n",
        "                \n",
        "                a_prev_slice = A_prev[i][vert_start: vert_end, horiz_start: horiz_end]\n",
        "\n",
        "                if mode == 'max':\n",
        "                    a[h, w] = np.max(a_prev_slice)\n",
        "                elif mode == 'avg':\n",
        "                    a[h, w] = np.mean(a_prev_slice)\n",
        "                        \n",
        "        A.append(a)\n",
        "\n",
        "    cache = (A_prev, hparameters)\n",
        "    \n",
        "    return A, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzxAVLbgq_Kk"
      },
      "source": [
        "conv_single_step — одно перемножение цветов картинки на матрицы, выявляющую границу.\n",
        "\n",
        "conv_forward — полное определение границ на всей фотографии.\n",
        "\n",
        "pool_forward — уменьшаем размер полученного массива.\n",
        "\n",
        "\n",
        "Отдельно отмечу значение строчек в функции conv_forward:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcASUFqKq1RY"
      },
      "source": [
        "(x0, x1, x2) = A_prev[i].shape\n",
        "A_prev_pad = A_prev[i][ \n",
        "    int(x0 / 4) : int(x0 * 3 / 4), \n",
        "    int(x1 / 4) : int(x1 * 3 / 4), \n",
        "    :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEitL6mYrQCn"
      },
      "source": [
        "Для анализа используем не всё изображение, а только его центральную часть, т.к. фокус фотоаппарата чаще наводится на центр. Если снимок четкий, то и центр будет четкий.\n",
        "\n",
        "Следующая функция определяет границы объектов на снимке, используя предыдущие функции:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvDboBHirThp"
      },
      "source": [
        "# main layer\n",
        "def borders(images, filter_size = 1, stride = 1, pool_stride = 2, pool_size = 2, z_max = []):\n",
        "    Wv = edges(filter_size, 'vert')\n",
        "    hparameters = {'pad': pad, 'stride': stride, 'pool_stride': pool_stride, 'f': pool_size, 'z_max': z_max}\n",
        "    Z, z_max_v, _ = conv_forward(images, Wv, hparameters)\n",
        "    \n",
        "    print('edge filter applied')\n",
        "    \n",
        "    hparameters_pool = {'stride': pool_stride, 'f': pool_size}\n",
        "    Av, _ = pool_forward(Z, hparameters_pool, mode = 'max')\n",
        "    \n",
        "    print('vertical filter applied')\n",
        "    \n",
        "    Wh = edges(filter_size, 'horiz')\n",
        "    hparameters = {'pad': pad, 'stride': stride, 'pool_stride': pool_stride, 'f': pool_size, 'z_max': z_max}\n",
        "    Z, z_max_h, _ = conv_forward(images, Wh, hparameters)\n",
        "    \n",
        "    print('edge filter applied')\n",
        "    \n",
        "    hparameters_pool = {'stride': pool_stride, 'f': pool_size}\n",
        "    Ah, _ = pool_forward(Z, hparameters_pool, mode = 'max')\n",
        "    \n",
        "    print('horizontal filter applied')   \n",
        "    \n",
        "    return [(Av[i] + Ah[i]) / 2 for i in range(len(Av))], list(map(np.max, zip(z_max_v, z_max_h)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFUhUQFOrX8G"
      },
      "source": [
        "Функция определяет вертикальные границы, затем горизонтальные, и возвращает среднее арифметическое обоих массивов.\n",
        "\n",
        "И основная функция для выдачи параметра четкости:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgbsJIkMraS8"
      },
      "source": [
        "# calculate borders of original and blurred images\n",
        "def orig_blur(images, filter_size = 1, stride = 3, pool_stride = 2, pool_size = 2, blur = 57):\n",
        "    z_max = []\n",
        "\n",
        "    img, z_max = borders(images, \n",
        "                         filter_size = filter_size, \n",
        "                         stride = stride, \n",
        "                         pool_stride = pool_stride, \n",
        "                         pool_size = pool_size\n",
        "                        )\n",
        "    print('original image borders is calculated')\n",
        "    \n",
        "    blurred_img = [cv2.GaussianBlur(x, (blur, blur), 0) for x in images]\n",
        "    print('images blurred')\n",
        "    \n",
        "    blurred, z_max = borders(blurred_img, \n",
        "                             filter_size = filter_size, \n",
        "                             stride = stride, \n",
        "                             pool_stride = pool_stride, \n",
        "                             pool_size = pool_size, \n",
        "                             z_max = z_max\n",
        "                            )\n",
        "    print('blurred image borders is calculated')\n",
        "\n",
        "    return [np.mean(orig) / np.mean(blurred) for (orig, blurred) in zip(img, blurred)], img, blurred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9xre-SrdcE"
      },
      "source": [
        "Вначале определяем границы оригинального изображения, затем размываем снимок, потом определяем границы размытой фотографии, и, наконец, считаем отношение средних арифметических границ оригинального изображения и размытого.\n",
        "\n",
        "Функция возвращает список коэффициентов четкости, массив границ оригинального снимка и массив границ размытого."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EePEGzaVrveC"
      },
      "source": [
        "Особенности подхода\n",
        "\n",
        "*   чем снимок четче, тем сильнее изменяется граница, а значит, тем выше будет параметр;\n",
        "* для разных нужд необходима разная четкость. Поэтому необходимо определять границы четкости самостоятельно: где-то коэффициент достаточной четких фотографий будет выше 7, где-то только выше 10;\n",
        "\n",
        "*   коэффициент зависит от яркости фотографии. Границы темных фотографий будут изменяться слабее, а значит, и коэффициент будет меньше. Получается, границы четкости нужно определять с учетом освещения, то есть для типовых фотографий;\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrMCed_arkyO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}